#!/usr/bin/env ruby
# encoding: utf-8
require 'prawn'
require 'open-uri'
require 'nokogiri'
require 'slop'

opts = Slop.parse do
  banner 'Usage: scrape [options]'

  on 'url=', 'Url with %s representing page number'
  on 'pages=', 'Total pages'
  on 'output=', 'Output file name'
end

root_url = opts[:url] # "http://ebooks.library.cornell.edu/cgi/t/text/pageviewer-idx?c=math&cc=math&idno=01260001&view=image&seq=%s"
domain = URI.parse(root_url.gsub("%s", "")).host

Prawn::Document.generate(opts[:output]) do
  opts[:pages].to_i.times do |i|
    i += 1
    page_url = sprintf(root_url, i)

    puts "Processing #{i}.. #{page_url}"

    begin
      html = Nokogiri::HTML(open(page_url))
      image_url = "http://#{domain}" + html.css("#page img")[0]["src"]

      puts "Downloading image.. #{image_url}"
      image open(image_url), scale: 0.67, position: :center
    rescue OpenURI::HTTPError => e
      puts "Got #{e.inspect}"
    end
  end
end
